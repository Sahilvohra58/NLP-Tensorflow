{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning file download...\n"
     ]
    }
   ],
   "source": [
    "from help_functions import download_and_unzip\n",
    "import pandas as pd\n",
    "\n",
    "download_and_unzip('https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip', 'getting_started.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(columns = ['keyword', 'location', 'id'], inplace = True)\n",
    "test_data.drop(columns = ['keyword', 'location', 'id'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features_train, features_val, labels_train, labels_val = train_test_split(train_data['text'].tolist(), \n",
    "                                                                            train_data['target'].tolist(), \n",
    "                                                                            test_size=0.2, \n",
    "                                                                            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "train_data = tf.data.Dataset.from_tensor_slices((features_train, labels_train)).repeat(2).shuffle(500).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_data = tf.data.Dataset.from_tensor_slices((features_val, labels_val)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'@NoahCRothman Bore him with minutiae serve bad champagne. He may just explode.'\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for text, target in train_data.take(1):\n",
    "    print(text[0].numpy())\n",
    "    print(target[0].numpy())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "textvectorizer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=10000, standardize='lower_and_strip_punctuation',\n",
    "    split='whitespace', ngrams=None, output_mode='int',\n",
    "    output_sequence_length=15, pad_to_max_tokens=False)\n",
    "\n",
    "textvectorizer.adapt(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(15,), dtype=int64, numpy=\n",
       "array([   7,   31,  936, 4290,  100,  566,  695,  108,  208,    5, 3960,\n",
       "        146, 1866,  423,   11], dtype=int64)>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textvectorizer(text[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = tf.keras.layers.Embedding(input_dim = 10000, \n",
    "                                            output_dim = 128, \n",
    "                                            embeddings_initializer='uniform', \n",
    "                                            input_length=15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DENSE LAYER MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "input = layers.Input(shape = (1,), dtype=\"string\")\n",
    "x = textvectorizer(input)\n",
    "x = embedding_layer(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "#x = tf.keras.layers.Dense(15, activation='relu')(x)\n",
    "output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.Model(input, output, name = 'model_Dense_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "381/381 [==============================] - 6s 14ms/step - loss: 0.5496 - accuracy: 0.7731 - val_loss: 0.5748 - val_accuracy: 0.7455 - lr: 1.0000e-04\n",
      "Epoch 2/5\n",
      "381/381 [==============================] - 5s 13ms/step - loss: 0.5113 - accuracy: 0.7973 - val_loss: 0.5521 - val_accuracy: 0.7634 - lr: 1.1220e-04\n",
      "Epoch 3/5\n",
      "381/381 [==============================] - 5s 14ms/step - loss: 0.4723 - accuracy: 0.8158 - val_loss: 0.5321 - val_accuracy: 0.7545 - lr: 1.2589e-04\n",
      "Epoch 4/5\n",
      "381/381 [==============================] - 5s 13ms/step - loss: 0.4348 - accuracy: 0.8337 - val_loss: 0.5161 - val_accuracy: 0.7768 - lr: 1.4125e-04\n",
      "Epoch 5/5\n",
      "381/381 [==============================] - 5s 14ms/step - loss: 0.3994 - accuracy: 0.8502 - val_loss: 0.5040 - val_accuracy: 0.7857 - lr: 1.5849e-04\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "\n",
    "import datetime\n",
    "log_dir = \"Tensorboard/Dense_Layer_Exp/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "callbacks = [\n",
    "             tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10 ** (epoch / 20), verbose=0),\n",
    "             tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",  \n",
    "                                                 factor=0.2, # multiply the learning rate by 0.2 (reduce by 5x)\n",
    "                                                 patience=2,\n",
    "                                                 verbose=1, # print out when learning rate goes down \n",
    "                                                 min_lr=1e-7),\n",
    "              tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',\n",
    "                                              patience=5, \n",
    "                                              verbose=0),\n",
    "              tf.keras.callbacks.ModelCheckpoint(\n",
    "                  filepath='Models_checkpoints/Dense_Layer_Exp/model_ep_{epoch:02d}_val_accuracy_{val_accuracy:.4f}.ckpt',\n",
    "                  # file path format: \"Model_checkpoint_Classification_2/cp-{epoch:02d}-{val_loss:.02f}.ckpt\"\n",
    "                  save_weights_only=True,\n",
    "                  verbose=0),\n",
    "            tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "                ]\n",
    "\n",
    "history = model.fit(train_data, \n",
    "                    epochs=5,\n",
    "                    steps_per_epoch = len(train_data),\n",
    "                    validation_data = val_data,\n",
    "                    validation_steps = int(0.15*len(val_data)),\n",
    "                    callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "381/381 [==============================] - 5s 13ms/step - loss: 0.3671 - accuracy: 0.8617 - val_loss: 0.4966 - val_accuracy: 0.7812 - lr: 1.5849e-04\n",
      "Epoch 6/10\n",
      "381/381 [==============================] - 5s 14ms/step - loss: 0.3378 - accuracy: 0.8731 - val_loss: 0.4924 - val_accuracy: 0.7857 - lr: 1.7783e-04\n",
      "Epoch 7/10\n",
      "381/381 [==============================] - 5s 13ms/step - loss: 0.3091 - accuracy: 0.8842 - val_loss: 0.4908 - val_accuracy: 0.7768 - lr: 1.9953e-04\n",
      "Epoch 8/10\n",
      "381/381 [==============================] - 5s 13ms/step - loss: 0.2810 - accuracy: 0.8977 - val_loss: 0.4921 - val_accuracy: 0.7723 - lr: 2.2387e-04\n",
      "Epoch 9/10\n",
      "379/381 [============================>.] - ETA: 0s - loss: 0.2535 - accuracy: 0.9115\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 5.023772828280926e-05.\n",
      "381/381 [==============================] - 5s 13ms/step - loss: 0.2535 - accuracy: 0.9115 - val_loss: 0.4980 - val_accuracy: 0.7679 - lr: 2.5119e-04\n",
      "Epoch 10/10\n",
      "381/381 [==============================] - 5s 14ms/step - loss: 0.2269 - accuracy: 0.9213 - val_loss: 0.5075 - val_accuracy: 0.7545 - lr: 2.8184e-04\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('Models_checkpoints\\Dense_Layer_Exp\\model_ep_05_val_accuracy_0.7857.ckpt')\n",
    "history_01 = model.fit(train_data, \n",
    "                    initial_epoch = 4,\n",
    "                    epochs=10,\n",
    "                    steps_per_epoch = len(train_data),\n",
    "                    validation_data = val_data,\n",
    "                    validation_steps = int(0.15*len(val_data)),\n",
    "                    callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x16f208b8040>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('Models_checkpoints\\Dense_Layer_Exp\\model_ep_06_val_accuracy_0.7857.ckpt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 1ms/step - loss: 0.4507 - accuracy: 0.8096\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4507176876068115, 0.8095863461494446]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = tf.round(tf.squeeze(model.predict(test_data))).numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8003939592908733,\n",
       " 'precision': 0.822429906542056,\n",
       " 'recall': 0.6779661016949152,\n",
       " 'F1-Score': 0.7432432432432432,\n",
       " '(tn, fp, fn, tp)': (779, 95, 209, 440)}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix, recall_score, f1_score\n",
    "\n",
    "def matrices_calc(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    (tn, fp, fn, tp) = confusion_matrix(y_true, y_pred).ravel()\n",
    "    #print(f'accuracy: {accuracy:.4f}\\nPrecision: {precision:.4f}\\nRecall: {recall}\\nF1-Score: {f1:.4f}\\n(tn, fp, fn, tp): {(tn, fp, fn, tp)}')\n",
    "    metrics = {'accuracy': accuracy,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'F1-Score': f1,\n",
    "                '(tn, fp, fn, tp)': (tn, fp, fn, tp)}\n",
    "    return metrics\n",
    "\n",
    "base_model_results = matrices_calc(labels_val, tf.round(tf.squeeze(model.predict(features_val))).numpy().tolist())\n",
    "base_model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LSTM LAYER MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = tf.keras.layers.Embedding(input_dim = 10000, \n",
    "                                            output_dim = 128, \n",
    "                                            embeddings_initializer='uniform', \n",
    "                                            input_length=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = layers.Input(shape = (1,), dtype=\"string\")\n",
    "x = textvectorizer(input)\n",
    "x = embedding_layer(x)\n",
    "x = layers.LSTM(64)(x)\n",
    "output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model_LSTM = tf.keras.Model(input, output, name = 'model_LSTM_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "381/381 [==============================] - 8s 17ms/step - loss: 0.5892 - accuracy: 0.6689 - val_loss: 0.5332 - val_accuracy: 0.7500 - lr: 1.0000e-04\n",
      "Epoch 2/5\n",
      "381/381 [==============================] - 7s 18ms/step - loss: 0.3157 - accuracy: 0.8722 - val_loss: 0.6005 - val_accuracy: 0.7054 - lr: 1.1220e-04\n",
      "Epoch 3/5\n",
      "380/381 [============================>.] - ETA: 0s - loss: 0.1984 - accuracy: 0.9308\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 2.517850953154266e-05.\n",
      "381/381 [==============================] - 6s 15ms/step - loss: 0.1982 - accuracy: 0.9310 - val_loss: 0.7464 - val_accuracy: 0.7054 - lr: 1.2589e-04\n",
      "Epoch 4/5\n",
      "381/381 [==============================] - 6s 17ms/step - loss: 0.1362 - accuracy: 0.9544 - val_loss: 0.8267 - val_accuracy: 0.7098 - lr: 1.4125e-04\n",
      "Epoch 5/5\n",
      "378/381 [============================>.] - ETA: 0s - loss: 0.1063 - accuracy: 0.9633\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 3.169786359649152e-05.\n",
      "381/381 [==============================] - 6s 15ms/step - loss: 0.1067 - accuracy: 0.9632 - val_loss: 0.9321 - val_accuracy: 0.6964 - lr: 1.5849e-04\n"
     ]
    }
   ],
   "source": [
    "model_LSTM.compile(loss = 'binary_crossentropy', optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "\n",
    "log_dir = \"Tensorboard/LSTM_Layer_Exp/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "callbacks = [\n",
    "             tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10 ** (epoch / 20), verbose=0),\n",
    "             tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",  \n",
    "                                                 factor=0.2, # multiply the learning rate by 0.2 (reduce by 5x)\n",
    "                                                 patience=2,\n",
    "                                                 verbose=1, # print out when learning rate goes down \n",
    "                                                 min_lr=1e-7),\n",
    "              tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',\n",
    "                                              patience=5, \n",
    "                                              verbose=0),\n",
    "              tf.keras.callbacks.ModelCheckpoint(\n",
    "                  filepath='Models_checkpoints/LSTM_Layer_Exp/model_ep_{epoch:02d}_val_accuracy_{val_accuracy:.4f}.ckpt',\n",
    "                  # file path format: \"Model_checkpoint_Classification_2/cp-{epoch:02d}-{val_loss:.02f}.ckpt\"\n",
    "                  save_weights_only=True,\n",
    "                  verbose=0),\n",
    "            tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "                ]\n",
    "\n",
    "history_LSTM = model_LSTM.fit(train_data, \n",
    "                    epochs=5,\n",
    "                    steps_per_epoch = len(train_data),\n",
    "                    validation_data = val_data,\n",
    "                    validation_steps = int(0.15*len(val_data)),\n",
    "                    callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 4ms/step - loss: 0.7857 - accuracy: 0.7597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7857215404510498, 0.7596848607063293]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LSTM.load_weights('Models_checkpoints\\LSTM_Layer_Exp\\model_ep_05_val_accuracy_0.6964.ckpt')\n",
    "model_LSTM.evaluate(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7596848325673013,\n",
       " 'precision': 0.7140695915279879,\n",
       " 'recall': 0.7272727272727273,\n",
       " 'F1-Score': 0.7206106870229007,\n",
       " '(tn, fp, fn, tp)': (685, 189, 177, 472)}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_LSTM = tf.round(tf.squeeze(model_LSTM.predict(test_data))).numpy().tolist()\n",
    "LSTM_model_results = matrices_calc(labels_val, tf.round(tf.squeeze(model_LSTM.predict(features_val))).numpy().tolist())\n",
    "LSTM_model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GRU LAYER MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = tf.keras.layers.Embedding(input_dim = 10000, \n",
    "                                            output_dim = 128, \n",
    "                                            embeddings_initializer='uniform', \n",
    "                                            input_length=15)\n",
    "\n",
    "\n",
    "input = layers.Input(shape = (1,), dtype=\"string\")\n",
    "x = textvectorizer(input)\n",
    "x = embedding_layer(x)\n",
    "x = layers.GRU(64)(x)\n",
    "output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model_GRU = tf.keras.Model(input, output, name = 'model_GRU_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "381/381 [==============================] - 8s 17ms/step - loss: 0.6585 - accuracy: 0.6014 - val_loss: 0.5889 - val_accuracy: 0.7545 - lr: 1.0000e-04\n",
      "Epoch 2/5\n",
      "381/381 [==============================] - 7s 18ms/step - loss: 0.3601 - accuracy: 0.8472 - val_loss: 0.5279 - val_accuracy: 0.7723 - lr: 1.1220e-04\n",
      "Epoch 3/5\n",
      "381/381 [==============================] - 7s 18ms/step - loss: 0.2068 - accuracy: 0.9196 - val_loss: 0.6428 - val_accuracy: 0.7500 - lr: 1.2589e-04\n",
      "Epoch 4/5\n",
      "380/381 [============================>.] - ETA: 0s - loss: 0.1317 - accuracy: 0.9516\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 2.825075061991811e-05.\n",
      "381/381 [==============================] - 7s 17ms/step - loss: 0.1316 - accuracy: 0.9517 - val_loss: 0.8262 - val_accuracy: 0.7098 - lr: 1.4125e-04\n",
      "Epoch 5/5\n",
      "381/381 [==============================] - 7s 18ms/step - loss: 0.0966 - accuracy: 0.9662 - val_loss: 0.9826 - val_accuracy: 0.6964 - lr: 1.5849e-04\n"
     ]
    }
   ],
   "source": [
    "model_GRU.compile(loss = 'binary_crossentropy', optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "\n",
    "log_dir = \"Tensorboard/GRU_Layer_Exp/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "callbacks = [\n",
    "             tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10 ** (epoch / 20), verbose=0),\n",
    "             tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",  \n",
    "                                                 factor=0.2, # multiply the learning rate by 0.2 (reduce by 5x)\n",
    "                                                 patience=2,\n",
    "                                                 verbose=1, # print out when learning rate goes down \n",
    "                                                 min_lr=1e-7),\n",
    "              tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',\n",
    "                                              patience=5, \n",
    "                                              verbose=0),\n",
    "              tf.keras.callbacks.ModelCheckpoint(\n",
    "                  filepath='Models_checkpoints/GRU_Layer_Exp/model_ep_{epoch:02d}_val_accuracy_{val_accuracy:.4f}.ckpt',\n",
    "                  # file path format: \"Model_checkpoint_Classification_2/cp-{epoch:02d}-{val_loss:.02f}.ckpt\"\n",
    "                  save_weights_only=True,\n",
    "                  verbose=0),\n",
    "            tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "                ]\n",
    "\n",
    "history_GRU = model_GRU.fit(train_data, \n",
    "                    epochs=5,\n",
    "                    steps_per_epoch = len(train_data),\n",
    "                    validation_data = val_data,\n",
    "                    validation_steps = int(0.15*len(val_data)),\n",
    "                    callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 2ms/step - loss: 0.8562 - accuracy: 0.7518\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.856205403804779, 0.7518056631088257]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_GRU.load_weights('Models_checkpoints\\GRU_Layer_Exp\\model_ep_05_val_accuracy_0.6964.ckpt')\n",
    "model_GRU.evaluate(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7518056467498359,\n",
       " 'precision': 0.6927453769559033,\n",
       " 'recall': 0.7503852080123267,\n",
       " 'F1-Score': 0.7204142011834321,\n",
       " '(tn, fp, fn, tp)': (658, 216, 162, 487)}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_GRU = tf.round(tf.squeeze(model_GRU.predict(test_data))).numpy().tolist()\n",
    "GRU_model_results = matrices_calc(labels_val, tf.round(tf.squeeze(model_GRU.predict(features_val))).numpy().tolist())\n",
    "GRU_model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BIDIRECTIONAL LAYER MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = tf.keras.layers.Embedding(input_dim = 10000, \n",
    "                                            output_dim = 128, \n",
    "                                            embeddings_initializer='uniform', \n",
    "                                            input_length=15)\n",
    "\n",
    "\n",
    "input = layers.Input(shape = (1,), dtype=\"string\")\n",
    "x = textvectorizer(input)\n",
    "x = embedding_layer(x)\n",
    "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
    "output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model_Bidirectional = tf.keras.Model(input, output, name = 'model_Bidirectional_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "381/381 [==============================] - 12s 23ms/step - loss: 0.5938 - accuracy: 0.6644 - val_loss: 0.5104 - val_accuracy: 0.7589 - lr: 1.0000e-04\n",
      "Epoch 2/5\n",
      "381/381 [==============================] - 8s 21ms/step - loss: 0.2949 - accuracy: 0.8768 - val_loss: 0.5723 - val_accuracy: 0.7768 - lr: 1.1220e-04\n",
      "Epoch 3/5\n",
      "381/381 [==============================] - ETA: 0s - loss: 0.1640 - accuracy: 0.9414\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 2.517850953154266e-05.\n",
      "381/381 [==============================] - 8s 21ms/step - loss: 0.1640 - accuracy: 0.9414 - val_loss: 0.7504 - val_accuracy: 0.7188 - lr: 1.2589e-04\n",
      "Epoch 4/5\n",
      "381/381 [==============================] - 7s 19ms/step - loss: 0.1010 - accuracy: 0.9672 - val_loss: 0.8658 - val_accuracy: 0.7277 - lr: 1.4125e-04\n",
      "Epoch 5/5\n",
      "380/381 [============================>.] - ETA: 0s - loss: 0.0784 - accuracy: 0.9737\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 3.169786359649152e-05.\n",
      "381/381 [==============================] - 8s 20ms/step - loss: 0.0785 - accuracy: 0.9736 - val_loss: 0.9703 - val_accuracy: 0.7098 - lr: 1.5849e-04\n"
     ]
    }
   ],
   "source": [
    "model_Bidirectional.compile(loss = 'binary_crossentropy', optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "\n",
    "log_dir = \"Tensorboard/Bidirectional_Layer_Exp/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "callbacks = [\n",
    "             tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10 ** (epoch / 20), verbose=0),\n",
    "             tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",  \n",
    "                                                 factor=0.2, # multiply the learning rate by 0.2 (reduce by 5x)\n",
    "                                                 patience=2,\n",
    "                                                 verbose=1, # print out when learning rate goes down \n",
    "                                                 min_lr=1e-7),\n",
    "              tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',\n",
    "                                              patience=5, \n",
    "                                              verbose=0),\n",
    "              tf.keras.callbacks.ModelCheckpoint(\n",
    "                  filepath='Models_checkpoints/Bidirectional_Layer_Exp/model_ep_{epoch:02d}_val_accuracy_{val_accuracy:.4f}.ckpt',\n",
    "                  # file path format: \"Model_checkpoint_Classification_2/cp-{epoch:02d}-{val_loss:.02f}.ckpt\"\n",
    "                  save_weights_only=True,\n",
    "                  verbose=0),\n",
    "            tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "                ]\n",
    "\n",
    "history_Bidirectional = model_Bidirectional.fit(train_data, \n",
    "                    epochs=5,\n",
    "                    steps_per_epoch = len(train_data),\n",
    "                    validation_data = val_data,\n",
    "                    validation_steps = int(0.15*len(val_data)),\n",
    "                    callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 3ms/step - loss: 0.8118 - accuracy: 0.7689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8118313550949097, 0.7688772082328796]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Bidirectional.load_weights('Models_checkpoints\\Bidirectional_Layer_Exp\\model_ep_05_val_accuracy_0.7098.ckpt')\n",
    "model_Bidirectional.evaluate(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.5292186474064347,\n",
       " 'precision': 0.45792079207920794,\n",
       " 'recall': 0.5701078582434514,\n",
       " 'F1-Score': 0.5078929306794783,\n",
       " '(tn, fp, fn, tp)': (436, 438, 279, 370)}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_Bidirectional = tf.round(tf.squeeze(model_Bidirectional.predict(test_data))).numpy().tolist()\n",
    "Bidirectional_model_results = matrices_calc(labels_val, tf.round(tf.squeeze(model_Bidirectional.predict(features_val))).numpy().tolist())\n",
    "Bidirectional_model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CNN LAYER MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = layers.Embedding(input_dim = 10000, \n",
    "                                    output_dim=128, \n",
    "                                    embeddings_initializer='uniform', \n",
    "                                    input_length=15)\n",
    "\n",
    "input = layers.Input(shape = (1,), dtype = 'string')\n",
    "x = textvectorizer(input)\n",
    "x = embedding_layer(x)\n",
    "x = layers.Conv1D(filters = 32, kernel_size = 5, activation = 'relu')(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "output = layers.Dense(1, activation='sigmoid')(x)\n",
    "model_CNN = tf.keras.Model(input, output, name = 'model_CNN')\n",
    "\n",
    "\n",
    "# input = layers.Input(shape = (1,), dtype=\"string\")\n",
    "# x = textvectorizer(input)\n",
    "# x = embedding_layer(x)\n",
    "# x = layers.Bidirectional(layers.LSTM(64))(x)\n",
    "# output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# model_Bidirectional = tf.keras.Model(input, output, name = 'model_Bidirectional_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "381/381 [==============================] - 6s 14ms/step - loss: 0.1486 - accuracy: 0.9516 - val_loss: 0.6537 - val_accuracy: 0.7188 - lr: 1.0000e-04\n",
      "Epoch 2/5\n",
      "381/381 [==============================] - 5s 14ms/step - loss: 0.1281 - accuracy: 0.9567 - val_loss: 0.7114 - val_accuracy: 0.7098 - lr: 1.1220e-04\n",
      "Epoch 3/5\n",
      "378/381 [============================>.] - ETA: 0s - loss: 0.1105 - accuracy: 0.9618\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 2.517850953154266e-05.\n",
      "381/381 [==============================] - 5s 14ms/step - loss: 0.1103 - accuracy: 0.9619 - val_loss: 0.7747 - val_accuracy: 0.7143 - lr: 1.2589e-04\n",
      "Epoch 4/5\n",
      "381/381 [==============================] - 6s 15ms/step - loss: 0.0956 - accuracy: 0.9648 - val_loss: 0.8464 - val_accuracy: 0.7054 - lr: 1.4125e-04\n",
      "Epoch 5/5\n",
      "380/381 [============================>.] - ETA: 0s - loss: 0.0834 - accuracy: 0.9692\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 3.169786359649152e-05.\n",
      "381/381 [==============================] - 5s 14ms/step - loss: 0.0835 - accuracy: 0.9691 - val_loss: 0.9180 - val_accuracy: 0.7098 - lr: 1.5849e-04\n"
     ]
    }
   ],
   "source": [
    "model_CNN.compile(loss = 'binary_crossentropy', optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "log_dir = \"Tensorboard/CNN_Layer_Exp/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "callbacks = [\n",
    "             tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10 ** (epoch / 20), verbose=0),\n",
    "             tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",  \n",
    "                                                 factor=0.2, # multiply the learning rate by 0.2 (reduce by 5x)\n",
    "                                                 patience=2,\n",
    "                                                 verbose=1, # print out when learning rate goes down \n",
    "                                                 min_lr=1e-7),\n",
    "              tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',\n",
    "                                              patience=5, \n",
    "                                              verbose=0),\n",
    "              tf.keras.callbacks.ModelCheckpoint(\n",
    "                  filepath='Models_checkpoints/CNN_Layer_Exp/model_ep_{epoch:02d}_val_accuracy_{val_accuracy:.4f}.ckpt',\n",
    "                  # file path format: \"Model_checkpoint_Classification_2/cp-{epoch:02d}-{val_loss:.02f}.ckpt\"\n",
    "                  save_weights_only=True,\n",
    "                  verbose=0),\n",
    "            tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "                ]\n",
    "history_CNN = model_CNN.fit(train_data,\n",
    "                epochs = 5,\n",
    "                steps_per_epoch = len(train_data),\n",
    "                validation_data = val_data,\n",
    "                validation_steps = int(0.15*len(val_data)),\n",
    "                callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 2ms/step - loss: 0.7704 - accuracy: 0.7603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7704440355300903, 0.7603414058685303]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_CNN.load_weights('Models_checkpoints\\CNN_Layer_Exp\\model_ep_05_val_accuracy_0.7098.ckpt')\n",
    "model_CNN.evaluate(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7603414313854235,\n",
       " 'precision': 0.721183800623053,\n",
       " 'recall': 0.7134052388289677,\n",
       " 'F1-Score': 0.7172734314484895,\n",
       " '(tn, fp, fn, tp)': (695, 179, 186, 463)}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_CNN = tf.round(tf.squeeze(model_CNN.predict(test_data))).numpy().tolist()\n",
    "CNN_model_results = matrices_calc(labels_val, tf.round(tf.squeeze(model_CNN.predict(features_val))).numpy().tolist())\n",
    "CNN_model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Pretrained Embeddings (transfer learning for NLP)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[ 0.05968354 -0.0160355  -0.02914821 -0.05212925  0.02219119 -0.04375772\n",
      " -0.02175827 -0.00285683  0.06052146  0.07888231  0.01754514 -0.00048307\n",
      " -0.00303452  0.03826183 -0.00717626 -0.066508    0.0197796  -0.07921368\n",
      " -0.05388004 -0.05932283 -0.03618991 -0.01079598 -0.05172737  0.03969066\n",
      " -0.08240779  0.07826601  0.06094696 -0.00315557  0.03758301 -0.01792064\n",
      "  0.01135455  0.08448923 -0.02728054 -0.0094435  -0.00829289  0.05783823\n",
      " -0.01559617 -0.00373469 -0.06719187 -0.05175795  0.00120352  0.05621188\n",
      " -0.00547588  0.04713415  0.02688809  0.04525854 -0.02508668 -0.01137264\n",
      " -0.0354304   0.03592852 -0.04883497 -0.03299141 -0.04440108 -0.03241378\n",
      " -0.07060566  0.00464731  0.05392553  0.02533009 -0.01198686  0.02648442\n",
      " -0.05612548 -0.06441199  0.03217232  0.04579192 -0.01634137  0.03273923\n",
      " -0.05343557  0.01555051  0.02573398  0.00867869 -0.0112708   0.01323091\n",
      " -0.0399779  -0.03572034  0.01663027  0.00909084  0.02308734  0.03665894\n",
      "  0.07215672  0.04339378  0.04741129  0.0183077   0.02695031 -0.06395172\n",
      "  0.01352294 -0.00823763 -0.04466709 -0.02281323 -0.02917396 -0.00881971\n",
      " -0.06885927  0.05987116 -0.05326559  0.0790982   0.02945225  0.08122709\n",
      " -0.0534214   0.07112421  0.03227122 -0.09154034  0.05923745 -0.06204582\n",
      " -0.02195525  0.08875643 -0.04200241  0.04401859 -0.05063793  0.02040784\n",
      "  0.03245187  0.06590131  0.04189294  0.00583273 -0.023462   -0.07787533\n",
      " -0.04075747 -0.02981336 -0.00663592  0.03615065  0.08805978  0.00885966\n",
      "  0.07300667  0.05976046  0.04476195 -0.04968236 -0.07100113  0.02242285\n",
      " -0.05879057 -0.03464671  0.06201865 -0.00421936 -0.03252375  0.06497421\n",
      " -0.05086384  0.07263526  0.00139585  0.0416285   0.00503773  0.04809688\n",
      "  0.04694967 -0.05387407  0.02723904 -0.06011928 -0.01410939 -0.02009457\n",
      " -0.02775423 -0.00734014  0.06436985  0.06621489 -0.0170688   0.00536123\n",
      "  0.00866095 -0.00208622 -0.04065555  0.01992573  0.03377075  0.02974286\n",
      " -0.02599602  0.00193236  0.02283483  0.00037971 -0.03536576  0.04531587\n",
      "  0.01880027 -0.03555898 -0.06857952 -0.01177694 -0.02072344 -0.04825439\n",
      " -0.03636359 -0.00273516 -0.06497978  0.06037941 -0.0310738   0.01356755\n",
      "  0.07133566 -0.04591028  0.05343076  0.00800601 -0.05162871  0.04199686\n",
      "  0.0352231  -0.04555564 -0.00522971 -0.05130734  0.06900262  0.06650269\n",
      " -0.01788498 -0.01606769  0.06680831  0.0146423   0.03628121  0.05043511\n",
      "  0.05325654 -0.02591303  0.03279797  0.00533919  0.03830574  0.06178965\n",
      "  0.06306303 -0.02997379 -0.09595028 -0.05299595 -0.0284384   0.08657481\n",
      " -0.00070433 -0.07306009  0.07155303  0.05186265 -0.01989826 -0.00828797\n",
      " -0.04241331  0.0202354   0.01640324 -0.01594064 -0.03375684  0.00652938\n",
      "  0.01985359  0.03763713  0.06640519  0.0197081  -0.00600813 -0.02788977\n",
      "  0.02906784 -0.01411756 -0.01726122  0.05707607 -0.03434201  0.03935229\n",
      "  0.00212241 -0.01517468  0.05266871  0.00510353  0.01704946  0.09734532\n",
      "  0.02114686  0.0217782   0.01270776  0.03584416 -0.02456514  0.03320449\n",
      " -0.07668623  0.06104106 -0.01780817  0.02838673 -0.02825714  0.01588808\n",
      " -0.06338206 -0.03814303 -0.03208932 -0.06442536 -0.03502322 -0.05217906\n",
      " -0.04406447 -0.03457087 -0.06984401 -0.03554093 -0.02463605 -0.03886775\n",
      " -0.01756455 -0.05327855  0.02125961 -0.03226131 -0.0753259   0.07180329\n",
      "  0.0636505   0.04228426  0.054061   -0.06788769 -0.01264228  0.05857532\n",
      " -0.04545779 -0.03343152  0.03978854  0.02535892 -0.00564819 -0.0237402\n",
      " -0.01681083  0.05990342  0.05251994 -0.03081512 -0.03818738 -0.01589187\n",
      " -0.05412985  0.05029397  0.03383511 -0.00906398  0.08108129  0.03666157\n",
      " -0.00029109 -0.05069609 -0.0384776   0.04392129  0.0837298  -0.08975136\n",
      "  0.05469194 -0.03023104 -0.01290382  0.08460616 -0.02144217  0.02300249\n",
      " -0.02885346  0.06557131  0.05451499 -0.02852753 -0.05756109 -0.05900906\n",
      "  0.03514135 -0.01020102 -0.04833471 -0.03733631 -0.05135794  0.04189046\n",
      "  0.03615478 -0.01528726  0.00828169 -0.03868679 -0.06864353  0.05151259\n",
      " -0.05182457  0.00943841 -0.0684858  -0.05172209  0.02354337 -0.01768425\n",
      " -0.00413072  0.02723611  0.02691621 -0.01228893 -0.00232815 -0.07430666\n",
      "  0.05159532  0.00964738  0.05227952  0.05373495 -0.03160302  0.05044705\n",
      " -0.01949954  0.0319625   0.04990831 -0.0036723   0.01169033  0.04652091\n",
      "  0.02261173 -0.01515721 -0.0915933   0.00255909  0.02983177  0.02038526\n",
      " -0.01559384  0.03271433 -0.0686139   0.06656989  0.01829047  0.0680488\n",
      " -0.01999295 -0.02572305 -0.09217118  0.01080314 -0.00094397 -0.02077589\n",
      " -0.0458667  -0.02544723  0.05842074 -0.04005666  0.07052458 -0.05286477\n",
      " -0.01522723 -0.03955287 -0.06231302  0.00156913  0.05126151 -0.04482846\n",
      " -0.00676308  0.06453966  0.05304316 -0.07005576  0.00916169 -0.05762391\n",
      " -0.00500059 -0.05225529  0.05925803  0.07041116  0.06444831  0.05850508\n",
      " -0.06869544 -0.0698025  -0.06085819  0.00297206  0.07713288 -0.0574507\n",
      "  0.05138547  0.06783103  0.04335155  0.06145744  0.06863491  0.03052394\n",
      " -0.00421991  0.03414559 -0.02622228  0.03636758 -0.02674752 -0.00369925\n",
      " -0.07886212  0.00653107  0.0022216   0.05320063 -0.0372893  -0.06944361\n",
      "  0.01599442 -0.02855576 -0.02708349  0.03366671 -0.00025183  0.05873493\n",
      " -0.03808416 -0.0210276   0.04872986  0.02691532  0.00450605  0.0027926\n",
      " -0.03212023 -0.00533511  0.02139234 -0.07846687  0.03004911 -0.07911232\n",
      " -0.01674275 -0.00347218 -0.08554932 -0.02039878 -0.05008358 -0.03062287\n",
      "  0.0507882  -0.0468829  -0.06706439 -0.00120109 -0.0131136   0.02699864\n",
      " -0.01384927  0.00605139  0.01625773  0.00395039 -0.02434724 -0.03748388\n",
      "  0.03801801  0.00849333  0.03581402 -0.07202658 -0.03922511 -0.08220812\n",
      " -0.02641817  0.00891359  0.00907238  0.01867029  0.05255021 -0.05863925\n",
      " -0.06451141 -0.05675428  0.00412307  0.01370686  0.05635281  0.03020123\n",
      "  0.04952501 -0.08416662 -0.05318447  0.03322184 -0.05366328 -0.03840516\n",
      "  0.07816199  0.06632835 -0.04671127 -0.02993603  0.04421344  0.02302398\n",
      " -0.03277405 -0.02144858 -0.0446843  -0.00186212  0.02458781  0.02482092\n",
      "  0.06742323  0.0101798   0.0153556  -0.03273953  0.06322818  0.01170409\n",
      "  0.02228365 -0.01815552  0.05408963  0.06669932 -0.06043949 -0.01057816\n",
      " -0.03271469  0.04819202  0.03356371  0.03154985  0.00441724  0.0147753\n",
      "  0.0006356   0.02270284  0.03828082 -0.05199739  0.02080673  0.05867682\n",
      "  0.01746198 -0.0740702  -0.02408902 -0.0698181   0.02683271  0.07703467\n",
      " -0.00915468 -0.06838535], shape=(512,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "embed_samples = embed(['I like to do NLP',\n",
    "                      \"When you call the universal sentence encoder on a sentence, it turns it into numbers.\"])\n",
    "\n",
    "print(embed_samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input = layers.Input(shape = (1,))\n",
    "embedding_layer = hub.KerasLayer('https://tfhub.dev/google/universal-sentence-encoder/4',\n",
    "                            input_shape = [],\n",
    "                            dtype = 'string',\n",
    "                            trainable = False,\n",
    "                            name = 'USE')\n",
    "\n",
    "model_USE = tf.keras.models.Sequential([\n",
    "            embedding_layer,\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "381/381 [==============================] - 7s 14ms/step - loss: 0.6442 - accuracy: 0.7318 - val_loss: 0.5888 - val_accuracy: 0.7946 - lr: 1.0000e-04\n",
      "Epoch 2/5\n",
      "381/381 [==============================] - 5s 12ms/step - loss: 0.5273 - accuracy: 0.7943 - val_loss: 0.4888 - val_accuracy: 0.8036 - lr: 1.1220e-04\n",
      "Epoch 3/5\n",
      "381/381 [==============================] - 4s 11ms/step - loss: 0.4603 - accuracy: 0.8028 - val_loss: 0.4437 - val_accuracy: 0.8036 - lr: 1.2589e-04\n",
      "Epoch 4/5\n",
      "381/381 [==============================] - 4s 12ms/step - loss: 0.4325 - accuracy: 0.8101 - val_loss: 0.4225 - val_accuracy: 0.8214 - lr: 1.4125e-04\n",
      "Epoch 5/5\n",
      "381/381 [==============================] - 6s 16ms/step - loss: 0.4180 - accuracy: 0.8151 - val_loss: 0.4107 - val_accuracy: 0.8348 - lr: 1.5849e-04\n"
     ]
    }
   ],
   "source": [
    "model_USE.compile(loss = 'binary_crossentropy', optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "log_dir = \"Tensorboard/USE_Layer_Exp/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "callbacks = [\n",
    "             tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10 ** (epoch / 20), verbose=0),\n",
    "             tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",  \n",
    "                                                 factor=0.2, # multiply the learning rate by 0.2 (reduce by 5x)\n",
    "                                                 patience=2,\n",
    "                                                 verbose=1, # print out when learning rate goes down \n",
    "                                                 min_lr=1e-7),\n",
    "              tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',\n",
    "                                              patience=5, \n",
    "                                              verbose=0),\n",
    "              tf.keras.callbacks.ModelCheckpoint(\n",
    "                  filepath='Models_checkpoints/USE_Layer_Exp/model_ep_{epoch:02d}_val_accuracy_{val_accuracy:.4f}.ckpt',\n",
    "                  # file path format: \"Model_checkpoint_Classification_2/cp-{epoch:02d}-{val_loss:.02f}.ckpt\"\n",
    "                  save_weights_only=True,\n",
    "                  verbose=0),\n",
    "            tf.keras.callbacks.TensorBoard(log_dir=log_dir)]\n",
    "\n",
    "history_USE = model_USE.fit(train_data,\n",
    "                epochs = 5,\n",
    "                steps_per_epoch = len(train_data),\n",
    "                validation_data = val_data,\n",
    "                validation_steps = int(0.15*len(val_data)),\n",
    "                callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x16f7dfa34c0>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_USE.load_weights('Models_checkpoints\\\\USE_Layer_Exp\\model_ep_05_val_accuracy_0.8348.ckpt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "381/381 [==============================] - 6s 15ms/step - loss: 0.4089 - accuracy: 0.8209 - val_loss: 0.4048 - val_accuracy: 0.8304 - lr: 1.5849e-04\n",
      "Epoch 6/10\n",
      "381/381 [==============================] - 5s 14ms/step - loss: 0.4026 - accuracy: 0.8235 - val_loss: 0.4013 - val_accuracy: 0.8393 - lr: 1.7783e-04\n",
      "Epoch 7/10\n",
      "381/381 [==============================] - 5s 14ms/step - loss: 0.3973 - accuracy: 0.8259 - val_loss: 0.3985 - val_accuracy: 0.8348 - lr: 1.9953e-04\n",
      "Epoch 8/10\n",
      "381/381 [==============================] - 5s 14ms/step - loss: 0.3926 - accuracy: 0.8305 - val_loss: 0.3978 - val_accuracy: 0.8348 - lr: 2.2387e-04\n",
      "Epoch 9/10\n",
      "381/381 [==============================] - 5s 14ms/step - loss: 0.3885 - accuracy: 0.8320 - val_loss: 0.3965 - val_accuracy: 0.8304 - lr: 2.5119e-04\n",
      "Epoch 10/10\n",
      "381/381 [==============================] - 5s 14ms/step - loss: 0.3844 - accuracy: 0.8333 - val_loss: 0.3962 - val_accuracy: 0.8259 - lr: 2.8184e-04\n"
     ]
    }
   ],
   "source": [
    "history_USE_1 = model_USE.fit(train_data,\n",
    "                initial_epoch = 4,\n",
    "                epochs = 10,\n",
    "                steps_per_epoch = len(train_data),\n",
    "                validation_data = val_data,\n",
    "                validation_steps = int(0.15*len(val_data)),\n",
    "                callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x16fee3b2d60>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_USE.load_weights('Models_checkpoints\\\\USE_Layer_Exp\\model_ep_06_val_accuracy_0.8393.ckpt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 7ms/step - loss: 0.4130 - accuracy: 0.8168\n",
      "[0.4129670262336731, 0.8168089389801025]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8168089297439265,\n",
       " 'precision': 0.8052805280528053,\n",
       " 'recall': 0.7519260400616333,\n",
       " 'F1-Score': 0.7776892430278886,\n",
       " '(tn, fp, fn, tp)': (756, 118, 161, 488)}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model_USE.evaluate(val_data))\n",
    "preds_USE = tf.round(tf.squeeze(model_USE.predict(test_data))).numpy().tolist()\n",
    "USE_model_results = matrices_calc(labels_val, tf.round(tf.squeeze(model_USE.predict(features_val))).numpy().tolist())\n",
    "USE_model_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRANSFERING ON 10% OF DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_90, feature_10, label_90, label_10 = train_test_split(features_train, labels_train,\n",
    "                                                            test_size=0.1,\n",
    "                                                            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_USE_10 = tf.keras.models.clone_model(model_USE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20/20 [==============================] - 4s 136ms/step - loss: 0.4494 - accuracy: 0.7997 - val_loss: 0.4452 - val_accuracy: 0.8214 - lr: 1.0000e-04\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 2s 113ms/step - loss: 0.4468 - accuracy: 0.7997 - val_loss: 0.4445 - val_accuracy: 0.8214 - lr: 1.1220e-04\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 2s 115ms/step - loss: 0.4449 - accuracy: 0.7997 - val_loss: 0.4440 - val_accuracy: 0.8170 - lr: 1.2589e-04\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 2s 113ms/step - loss: 0.4427 - accuracy: 0.7997 - val_loss: 0.4430 - val_accuracy: 0.8214 - lr: 1.4125e-04\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 2s 111ms/step - loss: 0.4401 - accuracy: 0.8013 - val_loss: 0.4422 - val_accuracy: 0.8214 - lr: 1.5849e-04\n"
     ]
    }
   ],
   "source": [
    "model_USE_10.compile(loss = 'binary_crossentropy', optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "log_dir = \"Tensorboard/USE_10_Layer_Exp/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "callbacks = [\n",
    "             tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10 ** (epoch / 20), verbose=0),\n",
    "             tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",  \n",
    "                                                 factor=0.2, # multiply the learning rate by 0.2 (reduce by 5x)\n",
    "                                                 patience=2,\n",
    "                                                 verbose=1, # print out when learning rate goes down \n",
    "                                                 min_lr=1e-7),\n",
    "              tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',\n",
    "                                              patience=5, \n",
    "                                              verbose=0),\n",
    "              tf.keras.callbacks.ModelCheckpoint(\n",
    "                  filepath='Models_checkpoints/USE_10_Layer_Exp/model_ep_{epoch:02d}_val_accuracy_{val_accuracy:.4f}.ckpt',\n",
    "                  # file path format: \"Model_checkpoint_Classification_2/cp-{epoch:02d}-{val_loss:.02f}.ckpt\"\n",
    "                  save_weights_only=True,\n",
    "                  verbose=0),\n",
    "            tf.keras.callbacks.TensorBoard(log_dir=log_dir)]\n",
    "\n",
    "history_USE_10 = model_USE_10.fit(feature_10, label_10,\n",
    "                epochs = 5,\n",
    "                #steps_per_epoch = len(train_data),\n",
    "                validation_data = val_data,\n",
    "                validation_steps = int(0.15*len(val_data)),\n",
    "                callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 8ms/step - loss: 0.4410 - accuracy: 0.8076\n",
      "[0.4409676194190979, 0.8076165318489075]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8076165462902167,\n",
       " 'precision': 0.7861736334405145,\n",
       " 'recall': 0.7534668721109399,\n",
       " 'F1-Score': 0.7694728560188828,\n",
       " '(tn, fp, fn, tp)': (741, 133, 160, 489)}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_USE_10.load_weights('Models_checkpoints\\\\USE_10_Layer_Exp\\model_ep_05_val_accuracy_0.8214.ckpt')\n",
    "print(model_USE_10.evaluate(val_data))\n",
    "preds_USE_10 = tf.round(tf.squeeze(model_USE_10.predict(test_data))).numpy().tolist()\n",
    "USE_10_results = matrices_calc(labels_val, tf.round(tf.squeeze(model_USE_10.predict(features_val))).numpy().tolist())\n",
    "USE_10_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparing all models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base model</th>\n",
       "      <th>LSTM model</th>\n",
       "      <th>GRU model</th>\n",
       "      <th>Bidirectional model</th>\n",
       "      <th>CNN model</th>\n",
       "      <th>USE model</th>\n",
       "      <th>USE 10% model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.800394</td>\n",
       "      <td>0.759685</td>\n",
       "      <td>0.751806</td>\n",
       "      <td>0.529219</td>\n",
       "      <td>0.760341</td>\n",
       "      <td>0.816809</td>\n",
       "      <td>0.807617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.82243</td>\n",
       "      <td>0.71407</td>\n",
       "      <td>0.692745</td>\n",
       "      <td>0.457921</td>\n",
       "      <td>0.721184</td>\n",
       "      <td>0.805281</td>\n",
       "      <td>0.786174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.677966</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.750385</td>\n",
       "      <td>0.570108</td>\n",
       "      <td>0.713405</td>\n",
       "      <td>0.751926</td>\n",
       "      <td>0.753467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-Score</th>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.720611</td>\n",
       "      <td>0.720414</td>\n",
       "      <td>0.507893</td>\n",
       "      <td>0.717273</td>\n",
       "      <td>0.777689</td>\n",
       "      <td>0.769473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(tn, fp, fn, tp)</th>\n",
       "      <td>(779, 95, 209, 440)</td>\n",
       "      <td>(685, 189, 177, 472)</td>\n",
       "      <td>(658, 216, 162, 487)</td>\n",
       "      <td>(436, 438, 279, 370)</td>\n",
       "      <td>(695, 179, 186, 463)</td>\n",
       "      <td>(756, 118, 161, 488)</td>\n",
       "      <td>(741, 133, 160, 489)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           base model            LSTM model  \\\n",
       "accuracy                     0.800394              0.759685   \n",
       "precision                     0.82243               0.71407   \n",
       "recall                       0.677966              0.727273   \n",
       "F1-Score                     0.743243              0.720611   \n",
       "(tn, fp, fn, tp)  (779, 95, 209, 440)  (685, 189, 177, 472)   \n",
       "\n",
       "                             GRU model   Bidirectional model  \\\n",
       "accuracy                      0.751806              0.529219   \n",
       "precision                     0.692745              0.457921   \n",
       "recall                        0.750385              0.570108   \n",
       "F1-Score                      0.720414              0.507893   \n",
       "(tn, fp, fn, tp)  (658, 216, 162, 487)  (436, 438, 279, 370)   \n",
       "\n",
       "                             CNN model             USE model  \\\n",
       "accuracy                      0.760341              0.816809   \n",
       "precision                     0.721184              0.805281   \n",
       "recall                        0.713405              0.751926   \n",
       "F1-Score                      0.717273              0.777689   \n",
       "(tn, fp, fn, tp)  (695, 179, 186, 463)  (756, 118, 161, 488)   \n",
       "\n",
       "                         USE 10% model  \n",
       "accuracy                      0.807617  \n",
       "precision                     0.786174  \n",
       "recall                        0.753467  \n",
       "F1-Score                      0.769473  \n",
       "(tn, fp, fn, tp)  (741, 133, 160, 489)  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "all_model_results = pd.DataFrame({'base model': base_model_results,\n",
    "                                    'LSTM model': LSTM_model_results,\n",
    "                                    'GRU model': GRU_model_results,\n",
    "                                    'Bidirectional model': Bidirectional_model_results,\n",
    "                                    'CNN model': CNN_model_results,\n",
    "                                    'USE model': USE_model_results,\n",
    "                                    'USE 10% model': USE_10_results})\n",
    "#all_model_results = all_model_results.transpose()\n",
    "all_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_model_results.transpose().plot(kind=\"bar\", figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_model_results.transpose().sort_values(\"F1-Score\", ascending=False)[\"F1-Score\"].plot(kind=\"bar\", figsize=(10, 7));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "combined_preds = (np.array(preds) + np.array(preds_CNN) + np.array(preds_USE))//3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., ..., 1., 0., 1.])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saving the hub model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_USE.save('model_USE.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model(\"model_USE.h5\", custom_objects={\"KerasLayer\": hub.KerasLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = loaded_model.predict(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob_lst = np.squeeze(predictions).tolist() # Prediction probability list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_idx_val_lst = [i for i, e in enumerate(labels_val) if e == 1] # index values of all the positives in the validation\n",
    "neg_idx_val_lst = [i for i, e in enumerate(labels_val) if e == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_val_pred_prob = [pred_prob_lst[i] for i in pos_idx_val_lst] # prediction probabilities of positives in validation set.\n",
    "neg_val_pred_prob = [pred_prob_lst[i] for i in neg_idx_val_lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(pos_val_pred_prob, rwidth=0.2, label = 'Actual value 0')\n",
    "plt.hist(neg_val_pred_prob, rwidth=0.2, label = 'Actual value 1')\n",
    "plt.title('Count VS Confidence')\n",
    "plt.legend();\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b6dd608ddd16ef8114cec5f050ad31736520bdbacef8568d33dc109fcf0153f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
